{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99972460",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation\n",
    "\n",
    "<p>Data cleaning and preparation are crucial steps in the data analysis process. These steps involve transforming raw data into a format that is suitable for analysis, and ensuring that the data is accurate, complete, and consistent. </p>\n",
    "\n",
    "The following are some key steps involved in our data cleaning and preparation process:\n",
    "\n",
    ">1. **Data Collection**: our raw dataset is from the 2021 BRFSS survey data done by the Center of Disease Control and Prevention based on over 400,000 survey participants in the United States. The original data file can be accessed at: https://www.cdc.gov/brfss/annual_data/annual_2021.html\n",
    "\n",
    "\n",
    ">2. **Data Extraction**: the survey dataset consists of 303 columns, which contain responses for different questions asked in the survey. To identify factors releted to our research area, i.e., hypertension, extensive research was conducted. After which, relevant variable columns are identified and extracted from the survey dataset.\n",
    "\n",
    "\n",
    ">3. **Data Cleaning**: numerous steps were taken to clean the dataset, including tackling missing values from survey respondents, dropping irrelevant responses and removing outliers for numeric data.\n",
    "\n",
    "\n",
    ">4. **Data Transformation**: after cleaning, the data is transformed into a format that is suitable for analysis. This involves creating new variables by manipulating existing columns and decoding categorical data into corresponding levels.\n",
    "\n",
    "\n",
    ">5. **Data Documentation & Export**: the last step involves a detailed documentation of the data. Our codebook can be found in the data description file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d471bf46",
   "metadata": {},
   "source": [
    "### Step 0: Convert the 2021 BRFSS data file to csv \n",
    "\n",
    "The original survey data file is only available in SAS Transport or ASCII Format. Thus, it has to be converted to csv format to be further processed using Pandas' libraries.\n",
    "\n",
    "The file conversion is conducted on our local machine through the code below:</br>\n",
    "`-m xport LLCP2021.xpt > raw.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "363cf854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb #for graphics\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e349531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_STATE</th>\n",
       "      <th>FMONTH</th>\n",
       "      <th>IDATE</th>\n",
       "      <th>IMONTH</th>\n",
       "      <th>IDAY</th>\n",
       "      <th>IYEAR</th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>SEQNO</th>\n",
       "      <th>_PSU</th>\n",
       "      <th>CTELENM1</th>\n",
       "      <th>...</th>\n",
       "      <th>_FRTRES1</th>\n",
       "      <th>_VEGRES1</th>\n",
       "      <th>_FRUTSU1</th>\n",
       "      <th>_VEGESU1</th>\n",
       "      <th>_FRTLT1A</th>\n",
       "      <th>_VEGLT1A</th>\n",
       "      <th>_FRT16A</th>\n",
       "      <th>_VEG23A</th>\n",
       "      <th>_FRUITE1</th>\n",
       "      <th>_VEGETE1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1192021</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2021</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2021000001</td>\n",
       "      <td>2.021000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1212021</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2021</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2021000002</td>\n",
       "      <td>2.021000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1212021</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2021</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2021000003</td>\n",
       "      <td>2.021000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1172021</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2021</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2021000004</td>\n",
       "      <td>2.021000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1152021</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2021</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2021000005</td>\n",
       "      <td>2.021000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _STATE  FMONTH    IDATE  IMONTH  IDAY  IYEAR  DISPCODE       SEQNO  \\\n",
       "0     1.0     1.0  1192021       1    19   2021    1100.0  2021000001   \n",
       "1     1.0     1.0  1212021       1    21   2021    1100.0  2021000002   \n",
       "2     1.0     1.0  1212021       1    21   2021    1100.0  2021000003   \n",
       "3     1.0     1.0  1172021       1    17   2021    1100.0  2021000004   \n",
       "4     1.0     1.0  1152021       1    15   2021    1100.0  2021000005   \n",
       "\n",
       "           _PSU  CTELENM1  ...  _FRTRES1  _VEGRES1  _FRUTSU1  _VEGESU1  \\\n",
       "0  2.021000e+09       1.0  ...       1.0       1.0     100.0     214.0   \n",
       "1  2.021000e+09       1.0  ...       1.0       1.0     100.0     128.0   \n",
       "2  2.021000e+09       1.0  ...       1.0       1.0     100.0      71.0   \n",
       "3  2.021000e+09       1.0  ...       1.0       1.0     114.0     165.0   \n",
       "4  2.021000e+09       1.0  ...       1.0       1.0     100.0     258.0   \n",
       "\n",
       "   _FRTLT1A  _VEGLT1A  _FRT16A  _VEG23A  _FRUITE1  _VEGETE1  \n",
       "0       1.0       1.0      1.0      1.0       0.0       0.0  \n",
       "1       1.0       1.0      1.0      1.0       0.0       0.0  \n",
       "2       1.0       2.0      1.0      1.0       0.0       0.0  \n",
       "3       1.0       1.0      1.0      1.0       0.0       0.0  \n",
       "4       1.0       1.0      1.0      1.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import raw survey dataset\n",
    "raw_dataset = pd.read_csv('raw.csv')\n",
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fad1c0",
   "metadata": {},
   "source": [
    "### Step 1: Extract columns that are relevant to our problem, i.e., hypertension analysis\n",
    "\n",
    "After extensive secondary research, the following factors are identified to have close relationship with hypertension:\n",
    "- **BMI**: The heavier we are, the more blood is required to supply oxygen and nutrients around our body, thus increasing the pressure on our blood vessels.\n",
    "\n",
    "- **Physical Exercise**: Individuals who lead sedentary lifestyles tend to have a higher heart rate than those who are physically active. This means that the heart needs to work harder. In addition, with little physical activity, there is a high likelihood of the person being overweight.\n",
    "\n",
    "- **Diabetes**: research has shown that people with diabetes are two to three times more likely to develop hypertension than those without diabetes. Furthermore, hypertension is a major risk factor for cardiovascular disease, which is the leading cause of death in people with diabetes. \n",
    "\n",
    "- **High Cholesterol**: Additionally, people with high cholesterol often develop high blood pressure. This is due to Cholesterol causing your arteries to become hard and narrow resulting in your heart straining much harder to pump blood through them. As a result, blood pressure increases.\n",
    "\n",
    "- **Junk Food Intake**: Junk foods such as processed foods, fast foods, sugary drinks, and snacks tend to be high in salt, sugar, unhealthy fats, and calories, but low in essential nutrients such as fiber, vitamins, and minerals. Overconsumption of these foods has been linked to several health problems, including hypertension\n",
    "\n",
    "- **Fruit Intake**: fruits are considered an important component of a healthy diet and are rich in nutrients such as vitamins, minerals, and antioxidants that are important for maintaining overall health. Some studies have suggested that increased fruit intake may be associated with a lower risk of hypertension.\n",
    "\n",
    "- **Vegetables Intake**: Vegetables are an important part of a healthy diet, and they are rich in nutrients such as vitamins, minerals, and fiber that are essential for maintaining overall health. Several studies have suggested that increased vegetable intake may be associated with a lower risk of hypertension.\n",
    "\n",
    "- **Education Level**: Several studies have shown that individuals with lower levels of education are more likely to develop hypertension compared to those with higher levels of education. For example, a study published in the Journal of Hypertension in 2014 found that individuals with a lower level of education had a higher risk of hypertension compared to those with a higher level of education.\n",
    "\n",
    "- **Alcohol Consumption Habit**: Drinking too much alcohol can raise blood pressure to unhealthy levels. Having more than three drinks in one sitting temporarily increases blood pressure, but repeated binge drinking can lead to long-term increased blood pressure.\n",
    "\n",
    "- **Smoker**: Smoking can raise our blood pressure temporarily and its chemicals can damage our artery walls, causing our arteries to narrow and stiffen.\n",
    "\n",
    "- **Other Mental Health Problem**: Several studies have shown that individuals with mental health conditions such as depression, anxiety, and chronic stress are at a higher risk of developing hypertension compared to those without these conditions.\n",
    "\n",
    "- **Other Physical Health Problem**: Based on multiple recent researches conduected, there are several medical conditions that are known to be risk factors for hypertension, including asthma, heart problem, arthritis.\n",
    "- **Age**: As people age, their risk of developing hypertension increases. This is because the blood vessels become stiffer and less elastic over time, which can lead to an increase in blood pressure. Additionally, as people age, they may be more likely to develop other medical conditions that are known to be risk factors for hypertension, such as obesity, diabetes, and kidney disease.\n",
    "\n",
    "- **Race**: Studies have shown that certain racial and ethnic groups, including African Americans, Hispanics, and Native Americans, are at a higher risk of developing hypertension compared to non-Hispanic whites. For example, according to the American Heart Association, African Americans have the highest prevalence of hypertension among any racial or ethnic group in the United States.\n",
    "\n",
    "\n",
    "Based on the factors identified through secondary research, relevant variables and data are extracted from the raw survey data file. Variables extracted include:\n",
    "1. _TOTINDA\n",
    "2. _BMI5\n",
    "3. DROCDY3_\n",
    "4. AVEDRNK3\n",
    "5. _RFBING5\n",
    "6. CHOLMED3\n",
    "7. FRENCHF1\n",
    "8. FRUTDA2_\n",
    "9. FTJUDA2_\n",
    "10. VEGEDA2_\n",
    "11. MENTHLTH\n",
    "12. PHYSHLTH\n",
    "13. _RFHYPE6\n",
    "14. DIABETE4\n",
    "15. _RFCHOL3\n",
    "\n",
    "For detailed description on the variables, please refer to our data description file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "befe7c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_TOTINDA</th>\n",
       "      <th>_BMI5</th>\n",
       "      <th>DROCDY3_</th>\n",
       "      <th>AVEDRNK3</th>\n",
       "      <th>_RFBING5</th>\n",
       "      <th>CHOLMED3</th>\n",
       "      <th>FRENCHF1</th>\n",
       "      <th>FRUTDA2_</th>\n",
       "      <th>FTJUDA2_</th>\n",
       "      <th>VEGEDA2_</th>\n",
       "      <th>...</th>\n",
       "      <th>_RFHYPE6</th>\n",
       "      <th>DIABETE4</th>\n",
       "      <th>_RFCHOL3</th>\n",
       "      <th>_MICHD</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>_CASTHM1</th>\n",
       "      <th>_RFSMOK3</th>\n",
       "      <th>_DRDXAR3</th>\n",
       "      <th>_IMPRACE</th>\n",
       "      <th>_AGE80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2829.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2873.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _TOTINDA   _BMI5  DROCDY3_  AVEDRNK3  _RFBING5  CHOLMED3  FRENCHF1  \\\n",
       "0       2.0  1454.0       0.0       NaN       1.0       1.0     203.0   \n",
       "1       1.0     NaN       0.0       NaN       1.0       1.0     555.0   \n",
       "2       2.0  2829.0       0.0       NaN       1.0       2.0     201.0   \n",
       "3       1.0  3347.0      14.0       3.0       2.0       2.0     204.0   \n",
       "4       1.0  2873.0       0.0       NaN       1.0       1.0     202.0   \n",
       "\n",
       "   FRUTDA2_  FTJUDA2_  VEGEDA2_  ...  _RFHYPE6  DIABETE4  _RFCHOL3  _MICHD  \\\n",
       "0     100.0       0.0     100.0  ...       1.0       3.0       2.0     2.0   \n",
       "1     100.0       0.0     100.0  ...       2.0       1.0       2.0     1.0   \n",
       "2     100.0       0.0      43.0  ...       2.0       1.0       1.0     1.0   \n",
       "3      43.0      71.0      71.0  ...       2.0       1.0       2.0     2.0   \n",
       "4     100.0       0.0     100.0  ...       1.0       1.0       2.0     1.0   \n",
       "\n",
       "   _EDUCAG  _CASTHM1  _RFSMOK3  _DRDXAR3  _IMPRACE  _AGE80  \n",
       "0      2.0       2.0       1.0       1.0       1.0    70.0  \n",
       "1      4.0       1.0       1.0       1.0       2.0    67.0  \n",
       "2      2.0       1.0       1.0       2.0       2.0    72.0  \n",
       "3      2.0       1.0       1.0       2.0       1.0    62.0  \n",
       "4      1.0       1.0       1.0       2.0       6.0    76.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract relevant variable columns from the raw data file\n",
    "hypertension_dataset = pd.DataFrame(raw_dataset[['_TOTINDA','_BMI5','DROCDY3_','AVEDRNK3','_RFBING5','CHOLMED3','FRENCHF1','FRUTDA2_','FTJUDA2_','VEGEDA2_','MENTHLTH','PHYSHLTH','_RFHYPE6','DIABETE4','_RFCHOL3','_MICHD','_EDUCAG','_CASTHM1','_RFSMOK3','_DRDXAR3','_IMPRACE','_AGE80']])\n",
    "hypertension_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce626afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438693, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypertension_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69bb239b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 438693 entries, 0 to 438692\n",
      "Data columns (total 22 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   _TOTINDA  438693 non-null  float64\n",
      " 1   _BMI5     391841 non-null  float64\n",
      " 2   DROCDY3_  438693 non-null  float64\n",
      " 3   AVEDRNK3  210422 non-null  float64\n",
      " 4   _RFBING5  438693 non-null  float64\n",
      " 5   CHOLMED3  377122 non-null  float64\n",
      " 6   FRENCHF1  400582 non-null  float64\n",
      " 7   FRUTDA2_  394742 non-null  float64\n",
      " 8   FTJUDA2_  394344 non-null  float64\n",
      " 9   VEGEDA2_  390165 non-null  float64\n",
      " 10  MENTHLTH  438691 non-null  float64\n",
      " 11  PHYSHLTH  438690 non-null  float64\n",
      " 12  _RFHYPE6  438693 non-null  float64\n",
      " 13  DIABETE4  438690 non-null  float64\n",
      " 14  _RFCHOL3  377542 non-null  float64\n",
      " 15  _MICHD    434058 non-null  float64\n",
      " 16  _EDUCAG   438693 non-null  float64\n",
      " 17  _CASTHM1  438693 non-null  float64\n",
      " 18  _RFSMOK3  438693 non-null  float64\n",
      " 19  _DRDXAR3  435797 non-null  float64\n",
      " 20  _IMPRACE  438693 non-null  float64\n",
      " 21  _AGE80    438693 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 73.6 MB\n"
     ]
    }
   ],
   "source": [
    "hypertension_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3e9b0d",
   "metadata": {},
   "source": [
    "### Step 2: Tackle the Missing Values\n",
    "\n",
    "Since the raw data file is from an actual survey conducted in the US, there are missing values in many variable columns because the survey respondents failed to provide answers for these questions.\n",
    "\n",
    "These missing values have to be tackled before we proceed with further analysis and model building. In our project, we opted for the simplest and the most direct way, which is to remove all the rows containing missing values. This method is acceptable in our case because there are `438,693` data points in the original data file and we would still have adequate amount of data for analysis after dropping the rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63e3017f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TOTINDA         0\n",
       "_BMI5        46852\n",
       "DROCDY3_         0\n",
       "AVEDRNK3    228271\n",
       "_RFBING5         0\n",
       "CHOLMED3     61571\n",
       "FRENCHF1     38111\n",
       "FRUTDA2_     43951\n",
       "FTJUDA2_     44349\n",
       "VEGEDA2_     48528\n",
       "MENTHLTH         2\n",
       "PHYSHLTH         3\n",
       "_RFHYPE6         0\n",
       "DIABETE4         3\n",
       "_RFCHOL3     61151\n",
       "_MICHD        4635\n",
       "_EDUCAG          0\n",
       "_CASTHM1         0\n",
       "_RFSMOK3         0\n",
       "_DRDXAR3      2896\n",
       "_IMPRACE         0\n",
       "_AGE80           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the number of NaN values in each variable column\n",
    "hypertension_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9872fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the rows with missing values\n",
    "hypertension_dataset.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01795b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TOTINDA    0\n",
       "_BMI5       0\n",
       "DROCDY3_    0\n",
       "AVEDRNK3    0\n",
       "_RFBING5    0\n",
       "CHOLMED3    0\n",
       "FRENCHF1    0\n",
       "FRUTDA2_    0\n",
       "FTJUDA2_    0\n",
       "VEGEDA2_    0\n",
       "MENTHLTH    0\n",
       "PHYSHLTH    0\n",
       "_RFHYPE6    0\n",
       "DIABETE4    0\n",
       "_RFCHOL3    0\n",
       "_MICHD      0\n",
       "_EDUCAG     0\n",
       "_CASTHM1    0\n",
       "_RFSMOK3    0\n",
       "_DRDXAR3    0\n",
       "_IMPRACE    0\n",
       "_AGE80      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the number of NaN values in each variable column again\n",
    "hypertension_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee358419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159613, 22)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the number of sample points left after dropping the NaN values. \n",
    "#In this case, we still have 159,613 rows left, which is more than sufficient for further analysis and model building.\n",
    "hypertension_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc849959",
   "metadata": {},
   "source": [
    "### Step 3: Tackling irrelevant data entries\n",
    "\n",
    "Many questions in the survey are designed to include options like \"Don’t know\" and \"Refused to tell\", which allows respondents to skip a question if they are uncomfortable or unwilling to provide an answer.\n",
    "\n",
    "However, data points with such input are not useful for our analysis and will not provide us with insighful information on the relationship between hypertension and the factors. Therefore, we chose to drop data rows with these irrelevant responses. \n",
    "\n",
    "For example, for the variable `_TOTINDA`, `9` indicates \"Don’t know/Refused/Missing\". Thus, rows with the value of 9 is dropped. \n",
    "\n",
    "At the same time, encoding for some variables is not intuitive enough. For instance, there are 2 numeric variable `MENTHLTH` and `PHYSHLTH`, which indicate the number of days in the last month in which the survey respondents had bad mental and physical health respectively. For these 2 variables, the value `88` indicates `None`, meaning that they do not have days with bad health. To make these numeric variables more intuitive, the numeric value `88` is replaced with `0`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6ef554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping rows with irrelevant survey responses. \n",
    "#Since each variale column has different encoding for \"Don’t know/Refused/Missing\" responses, we have to drop these values individually for each variable\n",
    "\n",
    "#_RFHYPE6\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['_RFHYPE6'] == 9].index, inplace=True) #Don’t know/Refused/Missing\n",
    "\n",
    "#_TOTINDA\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['_TOTINDA'] == 9].index, inplace=True) #Don’t know/Refused/Missing\n",
    "\n",
    "#_RFBING5\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['_RFBING5'] == 9].index, inplace=True) #Don’t know/Refused/Missing\n",
    "\n",
    "#CHOLMED3\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['CHOLMED3'] == 7].index, inplace=True) #Don’t know/Not Sure\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['CHOLMED3'] == 9].index, inplace=True) #Refused\n",
    "\n",
    "#FRENCHF1\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['FRENCHF1'] == 777].index, inplace=True) #Don’t know/Not Sure\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['FRENCHF1'] == 999].index, inplace=True) #Refused\n",
    "\n",
    "#MENTHLTH\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['MENTHLTH'] == 77].index, inplace=True) #Don’t know/Not sure\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['MENTHLTH'] == 99].index, inplace=True) #Refused\n",
    "        \n",
    "#PHYSHLTH\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['PHYSHLTH'] == 77].index, inplace=True) #Don’t know/Not sure\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['PHYSHLTH'] == 99].index, inplace=True) #Refused\n",
    "\n",
    "for ind in hypertension_dataset.index:\n",
    "    if hypertension_dataset['MENTHLTH'][ind]==88: #88 means None, so replace with 0\n",
    "        hypertension_dataset['MENTHLTH'][ind] = 0\n",
    "    if hypertension_dataset['PHYSHLTH'][ind]==88: #88 means None, so replace with 0\n",
    "        hypertension_dataset['PHYSHLTH'][ind] = 0\n",
    "\n",
    "#DIABETE4\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['DIABETE4'] == 9].index, inplace=True)\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['DIABETE4'] == 7].index, inplace=True)\n",
    "\n",
    "#_RFCHOL\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['_RFCHOL3'] == 9].index, inplace=True) #Don’t know/Refused/Missing\n",
    "\n",
    "#_EDUCAG\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['_EDUCAG'] == 9].index, inplace=True) #Don’t know/Refused/Missing\n",
    "\n",
    "#_CASTHM1 \n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['_CASTHM1'] == 9].index, inplace=True) #Don’t know/Refused/Missing\n",
    "\n",
    "#_RFSMOK3\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['_RFSMOK3'] == 9].index, inplace=True) #Refused\n",
    "\n",
    "#DROCDY3_\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['DROCDY3_'] == 900].index, inplace=True) #Refused\n",
    "\n",
    "#AVEDRNK3\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['AVEDRNK3'] == 77].index, inplace=True) #Refused\n",
    "hypertension_dataset.drop(hypertension_dataset[hypertension_dataset['AVEDRNK3'] == 99].index, inplace=True) #Refused\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b510c7b4",
   "metadata": {},
   "source": [
    "### Step 4: Create new variables by combining or transforming existing ones\n",
    "\n",
    "The survey conducted is very comprehensive and may contain several questions related to the same factor. Thus, we can combines related factors and create a new variable that is more useful for our analysis. In addition, the scale of some numeric answer may need to be adjusted before proceeding for further exploratory data analysis.\n",
    "\n",
    "In our project, we have created 2 new independent variables `AlchoIntake` and `FriesFreq` after merging and transforming original data columns. \n",
    "\n",
    ">`AlchoIntake` </br>\n",
    "In the extracted dataset, 2 variables appear to be related: `DROCDY3_` refers to drink occasions per day and `AVEDRNK3` refers how many drinks the survey respondents drink on average when they drink. Thus, we can combine these 2 variables to compute their alcohol consumption on a weekly basis, which would be a more useful numeric variable for analysis and model building.\n",
    "\n",
    ">`FriesFreq`<br/>\n",
    "`FRENCHF1` indicates the frequency of survey respondents eating any kind of fried potatoes, including french fries, home fries, or hash browns. However, this numeric value have different unit for different ranges, e.g., 101 - 199 is in days while 201 - 299 is in weeks. Thus, we have to standardise the units to days and calculate the respondents' average frequency of consuming french fries.\n",
    "\n",
    "\n",
    "The detailed manipulations can be found in the programs below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4160d5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/3835171372.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Alcho_Consumption['AlchoIntake'][ind] = Alcho_Consumption['DROCDY3_'][ind] * Alcho_Consumption['AVEDRNK3'][ind] * 7 /100 #compute weekly alcohol consumption\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/3835171372.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Alcho_Consumption['AlchoIntake'][ind] = 0\n"
     ]
    }
   ],
   "source": [
    "#Combine DROCDY3_ and AVEDRNK3 2 to compute alcohol consumption on a weekly basis and store it in a new variable called AlchoIntake\n",
    "\n",
    "#Extract varaibles and create a new empty column to store the result\n",
    "Alcho_Consumption = hypertension_dataset[['DROCDY3_','AVEDRNK3']]\n",
    "Alcho_Consumption = Alcho_Consumption.assign(AlchoIntake = \" \")\n",
    "\n",
    "#Compute weekly alcohol consumption of survey respondents, the logic is drived based on codebook provided by the original survey\n",
    "for ind in Alcho_Consumption.index:    \n",
    "    if Alcho_Consumption['DROCDY3_'][ind]==0 or Alcho_Consumption['AVEDRNK3'][ind] == 88.0: #means no alcohol consumption\n",
    "        Alcho_Consumption['AlchoIntake'][ind] = 0\n",
    "    else: \n",
    "        Alcho_Consumption['AlchoIntake'][ind] = Alcho_Consumption['DROCDY3_'][ind] * Alcho_Consumption['AVEDRNK3'][ind] * 7 /100 #compute weekly alcohol consumption \n",
    "\n",
    "#Convert the data type from object to float\n",
    "Alcho_Consumption['AlchoIntake'] = Alcho_Consumption['AlchoIntake'].astype(float)\n",
    "\n",
    "#Concatenate the new variable column with the current dataset\n",
    "hypertension_dataset = pd.concat([hypertension_dataset,Alcho_Consumption['AlchoIntake']],axis=1).reindex(hypertension_dataset.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47acb294",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/1139661966.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Fren_Fries['FriesFreq'][ind] = (Fren_Fries['FRENCHF1'][ind] - 200)/7\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/1139661966.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Fren_Fries['FriesFreq'][ind] = (Fren_Fries['FRENCHF1'][ind] - 300)/30\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/1139661966.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Fren_Fries['FriesFreq'][ind] = 0\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/1139661966.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Fren_Fries['FriesFreq'][ind] = 0.02  #just set to 0.02 which is lower than 1/30\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/1139661966.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Fren_Fries['FriesFreq'][ind] = Fren_Fries['FRENCHF1'][ind] - 100\n"
     ]
    }
   ],
   "source": [
    "#Standardise the unit of measurement for FRENCHF1 to days and store in a new vairable called FriesFreq\n",
    "\n",
    "#Extract varaibles and create a new empty column to store the result\n",
    "Fren_Fries = pd.DataFrame(hypertension_dataset['FRENCHF1'])\n",
    "Fren_Fries = Fren_Fries.assign(FriesFreq = \" \")\n",
    "\n",
    "#Convert unit of measurement to days, the logic is drived based on codebook provided by the original survey\n",
    "for ind in Fren_Fries.index:    \n",
    "    if 100 < Fren_Fries['FRENCHF1'][ind] < 200 : #original unit is in days\n",
    "        Fren_Fries['FriesFreq'][ind] = Fren_Fries['FRENCHF1'][ind] - 100\n",
    "        \n",
    "    elif 200 < Fren_Fries['FRENCHF1'][ind] < 300 :  #original unit in weeks\n",
    "        Fren_Fries['FriesFreq'][ind] = (Fren_Fries['FRENCHF1'][ind] - 200)/7\n",
    "    \n",
    "    elif Fren_Fries['FRENCHF1'][ind] == 300 :  #less than once a month\n",
    "        Fren_Fries['FriesFreq'][ind] = 0.02  #just set to 0.02 which is lower than 1/30\n",
    "        \n",
    "    elif 300 < Fren_Fries['FRENCHF1'][ind] < 400 :  #original unit in month\n",
    "        Fren_Fries['FriesFreq'][ind] = (Fren_Fries['FRENCHF1'][ind] - 300)/30\n",
    "        \n",
    "    elif Fren_Fries['FRENCHF1'][ind] == 555 :  #never eat \n",
    "        Fren_Fries['FriesFreq'][ind] = 0 \n",
    "\n",
    "#Convert the data type from object to float\n",
    "Fren_Fries['FriesFreq'] = Fren_Fries['FriesFreq'].astype(float)\n",
    "\n",
    "#Concatenate the new variable column with the current dataset\n",
    "hypertension_dataset = pd.concat([hypertension_dataset,Fren_Fries['FriesFreq']],axis=1).reindex(hypertension_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2e2291e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_TOTINDA</th>\n",
       "      <th>_BMI5</th>\n",
       "      <th>DROCDY3_</th>\n",
       "      <th>AVEDRNK3</th>\n",
       "      <th>_RFBING5</th>\n",
       "      <th>CHOLMED3</th>\n",
       "      <th>FRENCHF1</th>\n",
       "      <th>FRUTDA2_</th>\n",
       "      <th>FTJUDA2_</th>\n",
       "      <th>VEGEDA2_</th>\n",
       "      <th>...</th>\n",
       "      <th>_RFCHOL3</th>\n",
       "      <th>_MICHD</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>_CASTHM1</th>\n",
       "      <th>_RFSMOK3</th>\n",
       "      <th>_DRDXAR3</th>\n",
       "      <th>_IMPRACE</th>\n",
       "      <th>_AGE80</th>\n",
       "      <th>AlchoIntake</th>\n",
       "      <th>FriesFreq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3994.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2986.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3587.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2905.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    _TOTINDA   _BMI5  DROCDY3_  AVEDRNK3  _RFBING5  CHOLMED3  FRENCHF1  \\\n",
       "3        1.0  3347.0      14.0       3.0       2.0       2.0     204.0   \n",
       "9        1.0  3994.0      10.0       2.0       1.0       1.0     202.0   \n",
       "19       2.0  2986.0      29.0       1.0       1.0       1.0     302.0   \n",
       "22       2.0  3587.0      13.0       2.0       1.0       1.0     304.0   \n",
       "28       1.0  2905.0     100.0       1.0       1.0       2.0     202.0   \n",
       "\n",
       "    FRUTDA2_  FTJUDA2_  VEGEDA2_  ...  _RFCHOL3  _MICHD  _EDUCAG  _CASTHM1  \\\n",
       "3       43.0      71.0      71.0  ...       2.0     2.0      2.0       1.0   \n",
       "9      100.0       0.0      57.0  ...       1.0     2.0      2.0       1.0   \n",
       "19      29.0     200.0     100.0  ...       2.0     2.0      2.0       2.0   \n",
       "22       7.0       3.0      20.0  ...       2.0     2.0      2.0       1.0   \n",
       "28     100.0     100.0     100.0  ...       2.0     2.0      3.0       1.0   \n",
       "\n",
       "    _RFSMOK3  _DRDXAR3  _IMPRACE  _AGE80  AlchoIntake  FriesFreq  \n",
       "3        1.0       2.0       1.0    62.0         2.94   0.571429  \n",
       "9        1.0       1.0       1.0    65.0         1.40   0.285714  \n",
       "19       1.0       2.0       1.0    53.0         2.03   0.066667  \n",
       "22       2.0       2.0       1.0    68.0         1.82   0.133333  \n",
       "28       1.0       1.0       1.0    80.0         7.00   0.285714  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypertension_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa546c4",
   "metadata": {},
   "source": [
    "### Step 5: Decode categorical variables based on data description\n",
    "\n",
    "In the extracted data file, survey responses for categorical variables have been encoded using different numeric values, which explains why the data type for all columns are float64. However, the encoded number does not convey the original meaning of each categories and we have to refer to the codebook to interpret the value. Thus, we decided to decode the categorical variables based on our data documentation, so that it is more intuitive and esaier for human interpretation. \n",
    "\n",
    "Categorical variables include:\n",
    "1. _TOTINDA\n",
    "2. _RFBING5\n",
    "3. CHOLMED3\n",
    "4. _RFHYPE6\n",
    "5. DIABETE4\n",
    "6. _RFCHOL3\n",
    "7. _MICHD\n",
    "8. _EDUCAG\n",
    "9. _CASTHM1\n",
    "10. _RFSMOK3\n",
    "11. _DRDXAR3\n",
    "12. _IMPRACE\n",
    "13. _RFDRHV7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8694fe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/3621867782.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hypertension_dataset['_TOTINDA'][ind] = \"Yes\"\n",
      "/Users/wrx/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/3621867782.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hypertension_dataset['_RFBING5'][ind] = \"Yes\"\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/3621867782.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hypertension_dataset['CHOLMED3'][ind] = \"No\"\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/3621867782.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hypertension_dataset['DIABETE4'][ind] = \"Yes\"\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/3621867782.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hypertension_dataset['_RFCHOL3'][ind] = \"Yes\"\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/3621867782.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hypertension_dataset['_MICHD'][ind] = \"No\"\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/3621867782.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hypertension_dataset['_EDUCAG'][ind] = \"Graduated High School\"\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/3621867782.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hypertension_dataset['_CASTHM1'][ind] = \"No\"\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/3621867782.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hypertension_dataset['_RFSMOK3'][ind] = \"No\"\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/3621867782.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hypertension_dataset['_DRDXAR3'][ind] = \"No\"\n",
      "/var/folders/rq/pmx086v15tqccq0vw0tdmn200000gn/T/ipykernel_19283/3621867782.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hypertension_dataset['_IMPRACE'][ind] = \"White\"\n"
     ]
    }
   ],
   "source": [
    "#Decode the categorical variable \n",
    "#This has to be done manually because the encoding is not consistent, i.e., 1.0 is \"yes\" for some variables but \"no\" for others\n",
    "for ind in hypertension_dataset.index:    \n",
    "    #Decode _RFHYPE6 to be yes/no\n",
    "    if hypertension_dataset['_RFHYPE6'][ind]==1.0:\n",
    "        hypertension_dataset['_RFHYPE6'][ind] = \"No\"\n",
    "    elif hypertension_dataset['_RFHYPE6'][ind]==2.0:\n",
    "        hypertension_dataset['_RFHYPE6'][ind] = \"Yes\"\n",
    "    \n",
    "    #Decode _TOTINDA\n",
    "    if hypertension_dataset['_TOTINDA'][ind]==1.0:\n",
    "        hypertension_dataset['_TOTINDA'][ind] = \"Yes\"\n",
    "    elif hypertension_dataset['_TOTINDA'][ind]==2.0:\n",
    "        hypertension_dataset['_TOTINDA'][ind] = \"No\"\n",
    "        \n",
    "    #Decode _RFBING5\n",
    "    if hypertension_dataset['_RFBING5'][ind]==1.0:\n",
    "        hypertension_dataset['_RFBING5'][ind] = \"No\"\n",
    "    elif hypertension_dataset['_RFBING5'][ind]==2.0:\n",
    "        hypertension_dataset['_RFBING5'][ind] = \"Yes\"\n",
    "        \n",
    "    #Decode CHOLMED3\n",
    "    if hypertension_dataset['CHOLMED3'][ind]==1.0:\n",
    "        hypertension_dataset['CHOLMED3'][ind] = \"Yes\"\n",
    "    elif hypertension_dataset['CHOLMED3'][ind]==2.0:\n",
    "        hypertension_dataset['CHOLMED3'][ind] = \"No\"\n",
    "        \n",
    "    #Decode diabetes_dataset to be yes/no\n",
    "    if hypertension_dataset['DIABETE4'][ind]==1.0:\n",
    "        hypertension_dataset['DIABETE4'][ind] = \"Yes\"\n",
    "    elif hypertension_dataset['DIABETE4'][ind]==2.0:\n",
    "        hypertension_dataset['DIABETE4'][ind] = \"Yes\"\n",
    "    elif hypertension_dataset['DIABETE4'][ind]==3.0:\n",
    "        hypertension_dataset['DIABETE4'][ind] = \"No\"\n",
    "    elif hypertension_dataset['DIABETE4'][ind]==4.0:\n",
    "        hypertension_dataset['DIABETE4'][ind] = \"No\"\n",
    " \n",
    "    #Decode _RFCHOL3 to be yes/no\n",
    "    if hypertension_dataset['_RFCHOL3'][ind]==1.0:\n",
    "        hypertension_dataset['_RFCHOL3'][ind] = \"No\"\n",
    "    elif hypertension_dataset['_RFCHOL3'][ind]==2.0:\n",
    "        hypertension_dataset['_RFCHOL3'][ind] = \"Yes\"\n",
    "    \n",
    "    #Decode _MICHD to be yes/no\n",
    "    if hypertension_dataset['_MICHD'][ind]==1.0:\n",
    "        hypertension_dataset['_MICHD'][ind] = \"Yes\"\n",
    "    elif hypertension_dataset['_MICHD'][ind]==2.0:\n",
    "        hypertension_dataset['_MICHD'][ind] = \"No\"\n",
    "        \n",
    "    #Decode _EDUCAG \n",
    "    if hypertension_dataset['_EDUCAG'][ind]==1.0:\n",
    "        hypertension_dataset['_EDUCAG'][ind] = \"Did not graduate High School\"\n",
    "    elif hypertension_dataset['_EDUCAG'][ind]==2.0:\n",
    "        hypertension_dataset['_EDUCAG'][ind] = \"Graduated High School\"\n",
    "    elif hypertension_dataset['_EDUCAG'][ind]==3.0:\n",
    "        hypertension_dataset['_EDUCAG'][ind] = \"Attended College or Technical School\"\n",
    "    elif hypertension_dataset['_EDUCAG'][ind]==4.0:\n",
    "        hypertension_dataset['_EDUCAG'][ind] = \"Graduated from College or Technical School\" \n",
    "    \n",
    "    #Decode _CASTHM1 \n",
    "    if hypertension_dataset['_CASTHM1'][ind]==1.0:\n",
    "        hypertension_dataset['_CASTHM1'][ind] = \"No\"\n",
    "    elif hypertension_dataset['_CASTHM1'][ind]==2.0:\n",
    "        hypertension_dataset['_CASTHM1'][ind] = \"Yes\"\n",
    "        \n",
    "    #Decode _RFSMOK3\n",
    "    if hypertension_dataset['_RFSMOK3'][ind]==1.0:\n",
    "        hypertension_dataset['_RFSMOK3'][ind] = \"No\"\n",
    "    elif hypertension_dataset['_RFSMOK3'][ind]==2.0:\n",
    "        hypertension_dataset['_RFSMOK3'][ind] = \"Yes\"\n",
    "        \n",
    "    #Decode _DRDXAR3\n",
    "    if hypertension_dataset['_DRDXAR3'][ind]==1.0:\n",
    "        hypertension_dataset['_DRDXAR3'][ind] = \"Yes\"\n",
    "    elif hypertension_dataset['_DRDXAR3'][ind]==2.0:\n",
    "        hypertension_dataset['_DRDXAR3'][ind] = \"No\"\n",
    "\n",
    "    #Decode _IMPRACE \n",
    "    if hypertension_dataset['_IMPRACE'][ind]==1.0:\n",
    "        hypertension_dataset['_IMPRACE'][ind] = \"White\"\n",
    "    elif hypertension_dataset['_IMPRACE'][ind]==2.0:\n",
    "        hypertension_dataset['_IMPRACE'][ind] = \"Black\"\n",
    "    elif hypertension_dataset['_IMPRACE'][ind]==3.0:\n",
    "        hypertension_dataset['_IMPRACE'][ind] = \"Asian\"\n",
    "    elif hypertension_dataset['_IMPRACE'][ind]==4.0:\n",
    "        hypertension_dataset['_IMPRACE'][ind] = \"American Indian\" \n",
    "    elif hypertension_dataset['_IMPRACE'][ind]==5.0:\n",
    "        hypertension_dataset['_IMPRACE'][ind] = \"Hispanic\" \n",
    "    elif hypertension_dataset['_IMPRACE'][ind]==6.0:\n",
    "        hypertension_dataset['_IMPRACE'][ind] = \"Other Race\" \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1858faaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149931, 24)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypertension_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48be8e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 149931 entries, 3 to 438692\n",
      "Data columns (total 24 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   _TOTINDA     149931 non-null  object \n",
      " 1   _BMI5        149931 non-null  float64\n",
      " 2   DROCDY3_     149931 non-null  float64\n",
      " 3   AVEDRNK3     149931 non-null  float64\n",
      " 4   _RFBING5     149931 non-null  object \n",
      " 5   CHOLMED3     149931 non-null  object \n",
      " 6   FRENCHF1     149931 non-null  float64\n",
      " 7   FRUTDA2_     149931 non-null  float64\n",
      " 8   FTJUDA2_     149931 non-null  float64\n",
      " 9   VEGEDA2_     149931 non-null  float64\n",
      " 10  MENTHLTH     149931 non-null  float64\n",
      " 11  PHYSHLTH     149931 non-null  float64\n",
      " 12  _RFHYPE6     149931 non-null  object \n",
      " 13  DIABETE4     149931 non-null  object \n",
      " 14  _RFCHOL3     149931 non-null  object \n",
      " 15  _MICHD       149931 non-null  object \n",
      " 16  _EDUCAG      149931 non-null  object \n",
      " 17  _CASTHM1     149931 non-null  object \n",
      " 18  _RFSMOK3     149931 non-null  object \n",
      " 19  _DRDXAR3     149931 non-null  object \n",
      " 20  _IMPRACE     149931 non-null  object \n",
      " 21  _AGE80       149931 non-null  float64\n",
      " 22  AlchoIntake  149931 non-null  float64\n",
      " 23  FriesFreq    149931 non-null  float64\n",
      "dtypes: float64(12), object(12)\n",
      "memory usage: 32.6+ MB\n"
     ]
    }
   ],
   "source": [
    "hypertension_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd84208",
   "metadata": {},
   "source": [
    "### Step 6: Compute true values for numeric variables\n",
    "\n",
    "For some numeric data, their actual values are multipled by `100` before being stored into the data file, this is to prevent potential truncation and data loss. Thus, these variables have `2 implied decimal places` according to the survey codebook, e.g., `9999` actually means `99.99`. To get the actual values, we divided them by `100`. \n",
    "\n",
    "Numeric variables that need adjustment include:\n",
    "1. _BMI5\n",
    "2. FRUTDA2_\n",
    "3. FTJUDA2_\n",
    "4. VEGEDA2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f1525e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide \"implied 2 dp\" variables by 100\n",
    "hypertension_dataset['_BMI5'] = hypertension_dataset['_BMI5'].div(100).round(2)\n",
    "hypertension_dataset['FRUTDA2_'] = hypertension_dataset['FRUTDA2_'].div(100).round(2)\n",
    "hypertension_dataset['FTJUDA2_'] = hypertension_dataset['FTJUDA2_'].div(100).round(2)\n",
    "hypertension_dataset['VEGEDA2_'] = hypertension_dataset['VEGEDA2_'].div(100).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ca6ebb",
   "metadata": {},
   "source": [
    "### Step 7: Identify and remove outliers for numeric variables\n",
    "\n",
    "For numeric variables, it is essential to check the existence of outliers. In our case, since the survey are collected from US citizens, there may be situations where the survey respondents gives inaccurate or fake data, causing outliers to exist. These Outliers can affect data visualization, such as scatter plots or histograms to be skewed, making it difficult to interpret the data. At the same time, outliers can have a disproportionate impact on predictive models, leading to inaccurate predictions. \n",
    "\n",
    "Conducing outliers analysis allows us to identify errors and remove anomaliers in the data before proceeding with further exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04dcb445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_BMI5 has 4662 outliers.\n",
      "FriesFreq has 8523 outliers.\n",
      "FRUTDA2_ has 35992 outliers.\n",
      "FTJUDA2_ has 21025 outliers.\n",
      "VEGEDA2_ has 23032 outliers.\n",
      "AlchoIntake has 9780 outliers.\n"
     ]
    }
   ],
   "source": [
    "#Check number of outliers for each numeric variable\n",
    "def outliers_counter(df):\n",
    "        Q1=df.quantile(0.25)\n",
    "        Q3=df.quantile(0.75)\n",
    "        IQR=Q3-Q1\n",
    "        \n",
    "        count=0\n",
    "        for i in df:\n",
    "            if i<(Q1-1.5*IQR) or i>(Q3+1.5*IQR):\n",
    "                count+=1\n",
    "        \n",
    "        return count\n",
    "    \n",
    "print(\"_BMI5 has\",outliers_counter(hypertension_dataset[\"_BMI5\"]),\"outliers.\")\n",
    "print(\"FriesFreq has\",outliers_counter(hypertension_dataset[\"FriesFreq\"]),\"outliers.\")\n",
    "print(\"FRUTDA2_ has\",outliers_counter(hypertension_dataset[\"FRUTDA2_\"]),\"outliers.\")\n",
    "print(\"FTJUDA2_ has\",outliers_counter(hypertension_dataset[\"FTJUDA2_\"]),\"outliers.\")\n",
    "print(\"VEGEDA2_ has\",outliers_counter(hypertension_dataset[\"VEGEDA2_\"]),\"outliers.\")\n",
    "print(\"AlchoIntake has\",outliers_counter(hypertension_dataset[\"AlchoIntake\"]),\"outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b71ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the index of rows with outliers\n",
    "def outliers_index(df):\n",
    "        Q1=df.quantile(0.25)\n",
    "        Q3=df.quantile(0.75)\n",
    "        IQR=Q3-Q1\n",
    "        \n",
    "        index_list=[]\n",
    "        index=0\n",
    "        for i in df:\n",
    "            if i<(Q1-1.5*IQR) or i>(Q3+1.5*IQR):\n",
    "                index_list.append(index)\n",
    "            index+=1\n",
    "        return index_list\n",
    "\n",
    "#Remove rows with outliers\n",
    "numeric_vars = ['FTJUDA2_','_BMI5','FRUTDA2_','VEGEDA2_','FriesFreq','AlchoIntake']\n",
    "for var in numeric_vars:\n",
    "    if outliers_counter(hypertension_dataset[var])>0:\n",
    "        index_to_drop=outliers_index(hypertension_dataset[var])\n",
    "        hypertension_dataset = hypertension_dataset.drop(hypertension_dataset.index[index_to_drop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bccc78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_BMI5 has 323 outliers.\n",
      "FRNCHDA_ has 0 outliers.\n",
      "FRUTDA2_ has 0 outliers.\n",
      "FTJUDA2_ has 8120 outliers.\n",
      "VEGEDA2_ has 0 outliers.\n",
      "AlchoIntake has 4169 outliers.\n"
     ]
    }
   ],
   "source": [
    "#Since the removal of outliers is done in phase, new outliers may be created in some variables after rows are removed in other variables\n",
    "#Nevertheless, the number of outliers are reduced significantly.\n",
    "print(\"_BMI5 has\",outliers_counter(hypertension_dataset[\"_BMI5\"]),\"outliers.\")\n",
    "print(\"FRNCHDA_ has\",outliers_counter(hypertension_dataset[\"FriesFreq\"]),\"outliers.\")\n",
    "print(\"FRUTDA2_ has\",outliers_counter(hypertension_dataset[\"FRUTDA2_\"]),\"outliers.\")\n",
    "print(\"FTJUDA2_ has\",outliers_counter(hypertension_dataset[\"FTJUDA2_\"]),\"outliers.\")\n",
    "print(\"VEGEDA2_ has\",outliers_counter(hypertension_dataset[\"VEGEDA2_\"]),\"outliers.\")\n",
    "print(\"AlchoIntake has\",outliers_counter(hypertension_dataset[\"AlchoIntake\"]),\"outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f94ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96727065",
   "metadata": {},
   "source": [
    "### Cleaned Dataset\n",
    "\n",
    "After the data cleaning process, we have produced a cleaned dataset with `76,825` rows, which is still considered as adequate for subsequent data analysis and model building. \n",
    "\n",
    "This cleaned dataset is then exported to a new csv file called hypertension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34d50ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76825, 24)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypertension_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad77cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output cleaned dataset\n",
    "hypertension_dataset.to_csv(\"hypertension.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a22f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3554556a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
